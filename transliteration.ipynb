{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["## IMPORTING LIBRARIES"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import requests,zipfile,io\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","from torch import optim\n","import numpy as np\n","import random\n","import torch.nn.functional as F\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import wandb\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import csv"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## DOWNLOADING AND UNZIPPING DATA"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import requests  # Importing the requests library to make HTTP requests\n","import zipfile   # Importing the zipfile library to handle zip files\n","import io        # Importing the io library for input/output operations\n","\n","def download_data(url=\"https://drive.google.com/u/0/uc?id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw&export=download\"):\n","    # Make an HTTP GET request to the specified URL and store the response\n","    response = requests.get(url)\n","\n","    # Create a ZipFile object from the response content\n","    z = zipfile.ZipFile(io.BytesIO(response.content))\n","\n","    # Extract all the contents of the zip file\n","    z.extractall()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## METHODS FOR GETTING CHARACTERS FOR CORPUSS AND ADDING THEIR INDICES"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_corpus(data):\n","    eng_corpus = set()  # Set to store English characters\n","    hin_corpus = set()  # Set to store Hindi characters\n","    \n","    for i in range(0, len(data)):\n","        eng_word = data[0][i]  # English word at index i\n","        hin_word = data[1][i]  # Hindi word at index i\n","        \n","        # Add each character of the English word to the English corpus set\n","        for ch in eng_word:\n","            eng_corpus.add(ch)\n","        \n","        # Add each character of the Hindi word to the Hindi corpus set\n","        for ch in hin_word:\n","            hin_corpus.add(ch)\n","        \n","        # Add end delimiter characters to both corpora\n","        eng_corpus.add('#')\n","        hin_corpus.add('#')\n","        hin_corpus.add('$')\n","        eng_corpus.add('$')\n","        \n","        # Add start delimiter character to the Hindi corpus\n","        hin_corpus.add('^')\n","    \n","    return hin_corpus, eng_corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def word2index(data):\n","    hin_corpus, eng_corpus = get_corpus(data)  # Get Hindi and English corpora from data\n","    \n","    engchar_idx = {}  # Dictionary to map English characters to indices\n","    hinchar_idx = {}  # Dictionary to map Hindi characters to indices\n","    idx_engchar = {}  # Dictionary to map indices to English characters\n","    idx_hinchar = {}  # Dictionary to map indices to Hindi characters\n","    \n","    i = 0\n","    for char in eng_corpus:\n","        engchar_idx[char] = i  # Assign index i to English character char\n","        idx_engchar[i] = char  # Assign English character char to index i\n","        i += 1\n","    \n","    i = 0\n","    for char in hin_corpus:\n","        hinchar_idx[char] = i  # Assign index i to Hindi character char\n","        idx_hinchar[i] = char  # Assign Hindi character char to index i\n","        i += 1\n","    \n","    eng_vocab_size = len(eng_corpus)  # Vocabulary size of English corpus\n","    hin_vocab_size = len(hin_corpus)  # Vocabulary size of Hindi corpus\n","    \n","    return engchar_idx, hinchar_idx, idx_engchar, idx_hinchar, eng_vocab_size, hin_vocab_size\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## DATA PREPROCESSING"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def maxlen(data):\n","    maxlen_eng = 0  # Variable to store the maximum length of English words\n","    maxlen_hin = 0  # Variable to store the maximum length of Hindi words\n","    \n","    for i in range(0, len(data)):\n","        eng_word = data[0][i]  # English word at index i\n","        hin_word = data[1][i]  # Hindi word at index i\n","        \n","        # Update maxlen_eng if the length of eng_word is greater\n","        if len(eng_word) > maxlen_eng:\n","            maxlen_eng = len(eng_word)\n","        \n","        # Update maxlen_hin if the length of hin_word is greater\n","        if len(hin_word) > maxlen_hin:\n","            maxlen_hin = len(hin_word)\n","    \n","    return maxlen_eng, maxlen_hin"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def pre_process(data, eng_to_idx, hin_to_idx):\n","    eng = []  # List to store pre-processed English sentences\n","    hin = []  # List to store pre-processed Hindi sentences\n","    \n","    maxlen_eng, maxlen_hin = maxlen(data)  # Get the maximum lengths of English and Hindi words\n","    \n","    unknown = eng_to_idx['$']  # Index for unknown character in English corpus\n","    \n","    for i in range(0, len(data)):\n","        sz = 0  # Variable to track the size of the sentence\n","        eng_word = data[0][i]  # English word at index i\n","        hin_word = '^' + data[1][i]  # Add start delimiter (^) to Hindi word\n","        \n","        # Pad the English and Hindi words to their respective maximum lengths\n","        eng_word = eng_word.ljust(maxlen_eng + 1, '#')\n","        hin_word = hin_word.ljust(maxlen_hin + 1, '#')\n","        \n","        idx = []\n","        for char in eng_word:\n","            if eng_to_idx.get(char) is not None:\n","                idx.append(eng_to_idx[char])  # Append the index of the character if it exists in the corpus\n","            else:\n","                idx.append(unknown)  # Append the index of unknown character otherwise\n","        eng.append(idx)\n","        \n","        idx = []\n","        for char in hin_word:\n","            if hin_to_idx.get(char) is not None:\n","                idx.append(hin_to_idx[char])  # Append the index of the character if it exists in the corpus\n","            else:\n","                idx.append(unknown)  # Append the index of unknown character otherwise\n","        hin.append(idx)\n","    \n","    return eng, hin"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## LOADING OUR CUSTOM DATASET TO DATALOADER"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, train_x, train_y, transform=None):\n","        self.train_x = train_x  # Input data (train_x)\n","        self.train_y = train_y  # Target data (train_y)\n","        self.transform = transform  # Optional data transformation\n","        \n","    def __len__(self):\n","        return len(self.train_x)  # Return the length of the dataset\n","    \n","    def __getitem__(self, idx):\n","        if self.transform:\n","            sample = self.transform(sample)  # Apply the transformation (if any) to the sample\n","            \n","        # Return the input and target data tensors for the given index\n","        return torch.tensor(self.train_x[idx]).to(device), torch.tensor(self.train_y[idx]).to(device)\n","\n","def get_data():\n","    download_data()  # Download the data (assuming it has been implemented elsewhere)\n","    \n","    # Read the train, test, and validation datasets from CSV files\n","    train_df = pd.read_csv(\"aksharantar_sampled/hin/hin_train.csv\", header=None)\n","    test_df = pd.read_csv(\"aksharantar_sampled/hin/hin_test.csv\", header=None)\n","    val_df = pd.read_csv(\"aksharantar_sampled/hin/hin_valid.csv\", header=None)\n","    \n","    # Convert words to indices and retrieve vocabulary information\n","    eng_to_idx, hin_to_idx, idx_to_eng, idx_to_hin, input_len, target_len = word2index(train_df)\n","    \n","    # Return the datasets and vocabulary information\n","    return train_df, test_df, val_df, eng_to_idx, hin_to_idx, idx_to_eng, idx_to_hin, input_len, target_len\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Seq2Seq MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class EncoderGRU(nn.Module):\n","    def __init__(self,input_size,hidden_size,embedding_size,num_of_layers,batch_size,bi_directional,dropout_p=0.1):\n","        super(EncoderGRU,self).__init__()\n","        self.hidden_size=hidden_size\n","        self.batch_size=batch_size\n","        self.input_size=input_size\n","        self.embedding_size=embedding_size\n","        self.embedding=nn.Embedding(input_size,embedding_size)\n","        self.num_of_layers=num_of_layers\n","        self.bi_directional=bi_directional\n","        if(bi_directional==\"Yes\"):\n","            flag=True\n","        else:\n","            flag=False\n","        self.gru = nn.GRU(embedding_size,hidden_size,num_of_layers,bidirectional=flag)\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","    def forward(self,input,hidden):\n","        embedded=self.embedding(input).view(-1,self.batch_size, self.embedding_size)\n","        embedded = self.dropout(embedded)\n","        output,hidden=self.gru(embedded,hidden)\n","    \n","        if self.bi_directional==\"Yes\":\n","            hidden=hidden.resize(2,self.num_of_layers,self.batch_size,self.hidden_size)\n","            hidden=torch.add(hidden[0],hidden[1])/2\n","            \n","        return output,hidden\n","\n","    def initHidden(self):\n","        if(self.bi_directional==\"Yes\"):\n","            return torch.zeros(2*self.num_of_layers,self.batch_size,self.hidden_size,device=device)\n","        else:\n","            return torch.zeros(self.num_of_layers,self.batch_size,self.hidden_size,device=device)\n","\n","class DecoderGRU(nn.Module):\n","    def __init__(self, output_size,hidden_size, embedding_size, decoder_layers,batch_size,dropout_p=0.1):\n","        super(DecoderGRU, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding_size=embedding_size\n","        self.embedding = nn.Embedding(output_size, embedding_size)\n","        self.gru = nn.GRU(embedding_size,hidden_size, decoder_layers,dropout = dropout_p)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=2)\n","        self.batch_size=batch_size\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(-1, self.batch_size, self.embedding_size)\n","#         embedded = self.dropout(embedded)\n","        output, hidden = self.gru(embedded, hidden)\n","        output = self.softmax(self.out(output))\n","        return output, hidden"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class EncoderRNN(nn.Module):\n","    def __init__(self,input_size,hidden_size,embedding_size,num_of_layers,batch_size,bi_directional,dropout_p=0.1):\n","        super(EncoderRNN,self).__init__()\n","        self.hidden_size=hidden_size\n","        self.batch_size=batch_size\n","        self.input_size=input_size\n","        self.embedding_size=embedding_size\n","        self.embedding=nn.Embedding(input_size,embedding_size)\n","        self.num_of_layers=num_of_layers\n","        self.bi_directional=bi_directional\n","        if(bi_directional==\"Yes\"):\n","            flag=True\n","        else:\n","            flag=False\n","        self.rnn = nn.RNN(embedding_size,hidden_size,num_of_layers,bidirectional=flag)\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","    def forward(self,input,hidden):\n","        embedded=self.embedding(input).view(-1,self.batch_size, self.embedding_size)\n","        embedded = self.dropout(embedded)\n","        output,hidden=self.rnn(embedded,hidden)\n","    \n","        if self.bi_directional==\"Yes\":\n","            hidden=hidden.resize(2,self.num_of_layers,self.batch_size,self.hidden_size)\n","            hidden=torch.add(hidden[0],hidden[1])/2\n","            \n","        return output,hidden\n","\n","    def initHidden(self):\n","        if(self.bi_directional==\"Yes\"):\n","            return torch.zeros(2*self.num_of_layers,self.batch_size,self.hidden_size,device=device)\n","        else:\n","            return torch.zeros(self.num_of_layers,self.batch_size,self.hidden_size,device=device)\n","\n","class DecoderRNN(nn.Module):\n","    def __init__(self, output_size,hidden_size, embedding_size, decoder_layers,batch_size,dropout_p=0.1):\n","        super(DecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding_size=embedding_size\n","        self.embedding = nn.Embedding(output_size, embedding_size)\n","        self.rnn = nn.RNN(embedding_size,hidden_size, decoder_layers,dropout = dropout_p)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=2)\n","        self.batch_size=batch_size\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(-1, self.batch_size, self.embedding_size)\n","#         embedded = self.dropout(embedded)\n","        output, hidden = self.rnn(embedded, hidden)\n","        output = self.softmax(self.out(output))\n","        return output, hidden"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class EncoderLSTM(nn.Module):\n","    def __init__(self,input_size,hidden_size,embedding_size,num_of_layers,batch_size,bi_directional,dropout_p=0.1):\n","        super(EncoderLSTM,self).__init__()\n","        self.hidden_size=hidden_size\n","        self.batch_size=batch_size\n","        self.input_size=input_size\n","        self.embedding_size=embedding_size\n","        self.embedding=nn.Embedding(input_size,embedding_size)\n","        self.num_of_layers=num_of_layers\n","        self.bi_directional=bi_directional\n","        if(bi_directional==\"Yes\"):\n","            flag=True\n","        else:\n","            flag=False\n","        self.lstm = nn.LSTM(embedding_size,hidden_size,num_of_layers,bidirectional=flag)\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","    def forward(self,input,hidden,state):\n","        embedded=self.embedding(input).view(-1,self.batch_size, self.embedding_size)\n","        embedded = self.dropout(embedded)\n","        output,(hidden,state)=self.lstm(embedded,(hidden,state))\n","    \n","        if self.bi_directional==\"Yes\":\n","            hidden=hidden.resize(2,self.num_of_layers,self.batch_size,self.hidden_size)\n","            state=state.resize(2,self.num_of_layers,self.batch_size,self.hidden_size)\n","            hidden=torch.add(hidden[0],hidden[1])/2\n","            state=torch.add(state[0],hidden[1])/2\n","            \n","        return output,hidden,state\n","\n","    def initHidden(self):\n","        if(self.bi_directional==\"Yes\"):\n","            return torch.zeros(2*self.num_of_layers,self.batch_size,self.hidden_size,device=device)\n","        else:\n","            return torch.zeros(self.num_of_layers,self.batch_size,self.hidden_size,device=device)\n","    \n","    def initState(self):\n","        if(self.bi_directional==\"Yes\"):\n","            return torch.zeros(2*self.num_of_layers,self.batch_size,self.hidden_size,device=device)\n","        else:\n","            return torch.zeros(self.num_of_layers,self.batch_size,self.hidden_size,device=device)\n","\n","class DecoderLSTM(nn.Module):\n","    def __init__(self, output_size,hidden_size, embedding_size, decoder_layers,batch_size,dropout_p=0.1):\n","        super(DecoderLSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding_size=embedding_size\n","        self.embedding = nn.Embedding(output_size, embedding_size)\n","        self.lstm = nn.LSTM(embedding_size,hidden_size,decoder_layers,dropout = dropout_p)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=2)\n","        self.batch_size=batch_size\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","    def forward(self, input,hidden,state):\n","        embedded = self.embedding(input).view(-1, self.batch_size, self.embedding_size)\n","#         embedded = self.dropout(embedded)\n","        output,(hidden,state)=self.lstm(embedded,(hidden,state))\n","        output = self.softmax(self.out(output))\n","        return output,hidden,state"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## ATTENTION MECHANISM"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class AttnDecoder(nn.Module):\n","    def __init__(self,output_size,hidden_size,embedding_size,decoder_layers,batch_size,cell_type,dropout_p=0.1):\n","        super(AttnDecoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.batch_size=batch_size\n","        self.cell_type=cell_type\n","        self.embedding_size=embedding_size\n","        self.decoder_layers=decoder_layers\n","        \n","        self.embedding = nn.Embedding(self.output_size, self.embedding_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","\n","        self.U=nn.Linear(self.hidden_size,self.hidden_size,bias=False).to(device)\n","        self.W=nn.Linear(self.hidden_size,self.hidden_size,bias=False).to(device)\n","        self.V=nn.Linear(self.hidden_size,1,bias=False).to(device)\n","        \n","        self.linear=nn.Linear(self.hidden_size,output_size,bias=True)\n","        self.softmax=nn.Softmax(dim=1)\n","        self.softmax1=nn.LogSoftmax(dim=2)\n","        \n","        if(cell_type==\"GRU\"):\n","            self.gru = nn.GRU(self.embedding_size+self.hidden_size, self.hidden_size,self.decoder_layers,dropout = dropout_p)\n","        if(cell_type==\"LSTM\"):\n","            self.lstm = nn.LSTM(self.embedding_size+self.hidden_size, self.hidden_size,self.decoder_layers,dropout = dropout_p)\n","        if(cell_type==\"RNN\"):\n","            self.rnn = nn.RNN(self.embedding_size+self.hidden_size, self.hidden_size,self.decoder_layers,dropout = dropout_p)\n","\n","    def forward(self, input, hidden,encoder_outputs,word_length,state=None):\n","        embedded = self.embedding(input).view(-1,self.batch_size, self.embedding_size)\n","        T=word_length\n","        temp1=self.W(hidden[-1])\n","        temp2=self.U(encoder_outputs)\n","        c=torch.zeros(self.batch_size,1,self.hidden_size).to(device)\n","        temp1=temp1.unsqueeze(0)\n","\n","        e_j=self.V(F.tanh(temp1+temp2))\n","        alpha_j=self.softmax(e_j)\n","        \n","        c = torch.bmm(alpha_j.permute(1,2,0),encoder_outputs.permute(1,0,2))\n","        \n","        final_input=torch.cat((embedded[0],c.squeeze(1)),1).unsqueeze(0)\n","    \n","        final_input = F.relu(final_input)\n","        \n","        if(self.cell_type==\"GRU\"):\n","            output,hidden=self.gru(final_input,hidden)\n","        if(self.cell_type==\"RNN\"):\n","            output,hidden=self.rnn(final_input,hidden)\n","        if(self.cell_type==\"LSTM\"):\n","            output, (hidden,state) =self.lstm(final_input,(hidden,state))\n","        \n","        \n","        output1=self.softmax1(self.linear(output))\n","        if(self.cell_type==\"GRU\" or self.cell_type==\"RNN\"):\n","            return output1, hidden, alpha_j\n","        if(self.cell_type==\"LSTM\"):\n","            return output1, hidden, state, alpha_j"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train(train_data, encoder, decoder, loss_fun, encoder_optimizer, decoder_optimizer, encoder_layers, decoder_layers, batch_size, hidden_size, bi_directional, cell_type, attention):\n","    total_loss = 0\n","    teacher_forcing_ratio = 0.5\n","    \n","    # Iterate over the training data\n","    for i, (train_x, train_y) in enumerate(train_data):\n","        loss = 0\n","        encoder_optimizer.zero_grad()\n","        decoder_optimizer.zero_grad()\n","        train_x = train_x.T\n","        train_y = train_y.T\n","        timesteps = len(train_x)\n","        \n","        # Check the cell type (RNN, GRU, LSTM)\n","        if cell_type == 'GRU' or cell_type == 'RNN':\n","            # Initialize the hidden state of the encoder\n","            encoder_hidden = encoder.initHidden()\n","            \n","            # Pass the input through the encoder\n","            encoder_output, encoder_hidden = encoder(train_x, encoder_hidden)\n","            \n","            # Adjust decoder hidden state based on the number of layers\n","            if decoder_layers > encoder_layers:\n","                i = decoder_layers\n","                decoder_hidden = encoder_hidden\n","                \n","                while True:\n","                    if i == encoder_layers:\n","                        break\n","                    # Concatenate the two tensors along the first dimension\n","                    decoder_hidden = torch.cat([decoder_hidden, encoder_hidden[-1].unsqueeze(0)], dim=0)\n","                    i -= 1\n","            elif decoder_layers < encoder_layers:\n","                decoder_hidden = encoder_hidden[-decoder_layers:]\n","            else:\n","                decoder_hidden = encoder_hidden\n","        \n","            decoder_input = train_y[0]\n","            \n","            # Apply bidirectional averaging if specified\n","            if bi_directional == \"Yes\":\n","                split_tensor = torch.split(encoder_output, hidden_size, dim=-1)\n","                encoder_output = torch.add(split_tensor[0], split_tensor[1]) / 2\n","            \n","            # Determine whether to use teacher forcing\n","            use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","            \n","            if use_teacher_forcing:\n","                # Teacher forcing: feed the target as the next input\n","                for i in range(0, len(train_y)):\n","                    if attention == \"Yes\":\n","                        # Pass input, hidden state, and encoder output through the decoder with attention\n","                        decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_output, len(train_x))\n","                        loss += loss_fun(torch.squeeze(decoder_output), train_y[i])\n","                        decoder_input = train_y[i]\n","                    else:\n","                        # Pass input and hidden state through the decoder\n","                        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","                        loss += loss_fun(torch.squeeze(decoder_output), train_y[i])\n","                        decoder_input = train_y[i]  # Teacher forcing\n","            else:\n","                # Without teacher forcing: use the predicted output as the next input\n","                for i in range(0, len(train_y)):\n","                    if attention == \"Yes\":\n","                        decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_output, len(train_x))\n","                        max_prob, index = decoder_output.topk(1)\n","                        loss += loss_fun(torch.squeeze(decoder_output), train_y[i])\n","                        decoder_input = index\n","                    else:\n","                        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","                        max_prob, index = decoder_output.topk(1)\n","                        loss += loss_fun(torch.squeeze(decoder_output), train_y[i])\n","                        decoder_input = index\n","            \n","            loss.backward()\n","            encoder_optimizer.step()\n","            decoder_optimizer.step()\n","            total_loss += loss\n","        \n","        # Check the cell type (LSTM)\n","        if cell_type == 'LSTM':\n","            encoder_hidden = encoder.initHidden()\n","            encoder_state = encoder.initState()\n","            \n","            encoder_output, encoder_hidden, encoder_state = encoder(train_x, encoder_hidden, encoder_state)\n","        \n","            if decoder_layers > encoder_layers:\n","                i = decoder_layers\n","                decoder_hidden = encoder_hidden\n","                decoder_state = encoder_state\n","                \n","                while True:\n","                    if i == encoder_layers:\n","                        break\n","                    # Concatenate the two tensors along the first dimension\n","                    decoder_hidden = torch.cat([decoder_hidden, encoder_hidden[-1].unsqueeze(0)], dim=0)\n","                    decoder_state = torch.cat([decoder_state, encoder_state[-1].unsqueeze(0)], dim=0)\n","                    i -= 1\n","            elif decoder_layers < encoder_layers:\n","                decoder_hidden = encoder_hidden[-decoder_layers:]\n","                decoder_state = encoder_state[-decoder_layers:]\n","            else:\n","                decoder_hidden = encoder_hidden\n","                decoder_state = encoder_state\n","            \n","            if bi_directional == \"Yes\":\n","                split_tensor = torch.split(encoder_output, hidden_size, dim=-1)\n","                encoder_output = torch.add(split_tensor[0], split_tensor[1]) / 2\n","            \n","            decoder_input = train_y[0]\n","            use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","            \n","            if use_teacher_forcing:\n","                for i in range(0, len(train_y)):\n","                    if attention == \"Yes\":\n","                        decoder_output, decoder_hidden, decoder_state, attn_weights = decoder(decoder_input, decoder_hidden, encoder_output, len(train_x), decoder_state)\n","                        loss += loss_fun(torch.squeeze(decoder_output), train_y[i])\n","                        decoder_input = train_y[i]\n","                    else:\n","                        decoder_output, decoder_hidden, decoder_state = decoder(decoder_input, decoder_hidden, decoder_state)\n","                        loss += loss_fun(torch.squeeze(decoder_output), train_y[i])\n","                        decoder_input = train_y[i]  # Teacher forcing\n","            else:\n","                for i in range(0, len(train_y)):\n","                    if attention == \"Yes\":\n","                        decoder_output, decoder_hidden, decoder_state, attn_weights = decoder(decoder_input, decoder_hidden, encoder_output, len(train_x), decoder_state)\n","                        max_prob, index = decoder_output.topk(1)\n","                        loss += loss_fun(torch.squeeze(decoder_output), train_y[i])\n","                        decoder_input = index\n","                    else:\n","                        decoder_output, decoder_hidden, decoder_state = decoder(decoder_input, decoder_hidden, decoder_state)\n","                        max_prob, index = decoder_output.topk(1)\n","                        loss += loss_fun(torch.squeeze(decoder_output), train_y[i])\n","                        decoder_input = index\n","            \n","            loss.backward()\n","            encoder_optimizer.step()\n","            decoder_optimizer.step()\n","            total_loss += loss\n","        \n","    return total_loss.item() / len(train_y), encoder, decoder\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_iter(input_data, val_data, val_y, input_len, target_len, epochs, batch_size, embedding_size, encoder_layers, decoder_layers, hidden_size, cell_type, bi_directional, dropout, attention, beam_size=0):\n","    lr = 0.001\n","    \n","    # Initialize the encoder and decoder based on the cell type and attention\n","    if cell_type == 'GRU':\n","        encoder = EncoderGRU(input_len, hidden_size, embedding_size, encoder_layers, batch_size, bi_directional, dropout).to(device)\n","        if attention == \"Yes\":\n","            decoder = AttnDecoder(target_len, hidden_size, embedding_size, decoder_layers, batch_size, cell_type, dropout).to(device)\n","        else:\n","            decoder = DecoderGRU(target_len, hidden_size, embedding_size, decoder_layers, batch_size, dropout).to(device)\n","    elif cell_type == 'RNN':\n","        encoder = EncoderRNN(input_len, hidden_size, embedding_size, encoder_layers, batch_size, bi_directional, dropout).to(device)\n","        if attention == \"Yes\":\n","            decoder = AttnDecoder(target_len, hidden_size, embedding_size, decoder_layers, batch_size, cell_type, dropout).to(device)\n","        else:\n","            decoder = DecoderRNN(target_len, hidden_size, embedding_size, decoder_layers, batch_size, dropout).to(device)\n","    elif cell_type == 'LSTM':\n","        encoder = EncoderLSTM(input_len, hidden_size, embedding_size, encoder_layers, batch_size, bi_directional, dropout).to(device)\n","        if attention == \"Yes\":\n","            decoder = AttnDecoder(target_len, hidden_size, embedding_size, decoder_layers, batch_size, cell_type, dropout).to(device)\n","        else:\n","            decoder = DecoderLSTM(target_len, hidden_size, embedding_size, decoder_layers, batch_size, dropout).to(device)\n","    \n","    encoder_optimizer = optim.Adam(encoder.parameters(), lr)\n","    decoder_optimizer = optim.Adam(decoder.parameters(), lr)\n","    loss_fun = nn.CrossEntropyLoss(reduction=\"sum\")\n","    epoch_train_loss = []\n","    epoch_val_loss = []\n","    epoch_val_acc = []\n","    \n","    # Iterate over the epochs\n","    for i in range(0, epochs):\n","        loss, encoder, decoder = train(input_data, encoder, decoder, loss_fun, encoder_optimizer, decoder_optimizer, encoder_layers, decoder_layers, batch_size, hidden_size, bi_directional, cell_type, attention)\n","        val_predictions, val_loss, attn_weights = eval(val_data, encoder, decoder, encoder_layers, decoder_layers, batch_size, hidden_size, bi_directional, cell_type, attention)\n","        \n","        epoch_val_loss.append(val_loss)\n","        epoch_train_loss.append(loss / 51200)  # train_data has 51200 samples\n","        \n","        val_acc = accuracy(val_predictions, val_y)\n","        epoch_val_acc.append(val_acc)\n","        \n","        print(loss / 51200, val_loss, val_acc)\n","    \n","    return epoch_train_loss, epoch_val_loss, epoch_val_acc, encoder, decoder, encoder_layers, decoder_layers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def eval(input_data, encoder, decoder, encoder_layers, decoder_layers, batch_size, hidden_size, bi_directional, cell_type, attention, build_matrix=False):\n","    with torch.no_grad():\n","        loss_fun = nn.CrossEntropyLoss(reduction=\"sum\")\n","        total_loss = 0\n","        pred_words = list()\n","        attention_matrix = []\n","        \n","        for x, y in input_data:\n","            attn = []\n","            loss = 0\n","            decoder_words = []\n","            x = x.T\n","            y = y.T\n","            \n","            # Initialize the encoder hidden state\n","            encoder_hidden = encoder.initHidden()\n","            \n","            # Get the number of timesteps in the input sequence\n","            timesteps = len(x)\n","            \n","            if cell_type == 'GRU' or cell_type == 'RNN':\n","                # Run the input sequence through the encoder\n","                encoder_hidden = encoder.initHidden()\n","                encoder_output, encoder_hidden = encoder(x, encoder_hidden)\n","                \n","                if decoder_layers > encoder_layers:\n","                    i = decoder_layers\n","                    decoder_hidden = encoder_hidden\n","                    \n","                    while True:\n","                        if i == encoder_layers:\n","                            break\n","                        # Concatenate the encoder hidden state to match the decoder layers\n","                        decoder_hidden = torch.cat([decoder_hidden, encoder_hidden[-1].unsqueeze(0)], dim=0)\n","                        i -= 1\n","                \n","                elif decoder_layers < encoder_layers:\n","                    decoder_hidden = encoder_hidden[-decoder_layers:]\n","                else:\n","                    decoder_hidden = encoder_hidden\n","                \n","                decoder_input = y[0]\n","                \n","                if bi_directional == \"Yes\":\n","                    # Split the encoder output tensor into two parts along the last dimension\n","                    split_tensor = torch.split(encoder_output, hidden_size, dim=-1)\n","                    # Average the two parts\n","                    encoder_output = torch.add(split_tensor[0], split_tensor[1]) / 2\n","                \n","                # Run the decoder for each timestep in the output sequence\n","                for i in range(0, len(y)):\n","                    if attention == \"Yes\":\n","                        decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_output, len(x))\n","                        max_prob, index = decoder_output.topk(1)\n","                        loss += loss_fun(torch.squeeze(decoder_output), y[i])\n","                        index = index.squeeze()\n","                        decoder_input = index\n","                        decoder_words.append(index.tolist())\n","                        if build_matrix:\n","                            attn.append(attn_weights)\n","                    else:\n","                        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","                        max_prob, index = decoder_output.topk(1)\n","                        loss += loss_fun(torch.squeeze(decoder_output), y[i])\n","                        index = index.squeeze()\n","                        decoder_input = index\n","                        decoder_words.append(index.tolist())\n","                \n","                if build_matrix:\n","                    attention_matrix = torch.cat(tuple(x for x in attn), dim=2).to(device)\n","                \n","                decoder_words = np.array(decoder_words)\n","                pred_words.append(decoder_words.T)\n","                total_loss += loss.item()\n","            \n","            if cell_type == 'LSTM':\n","                # Run the input sequence through the encoder\n","                encoder_hidden = encoder.initHidden()\n","                encoder_state = encoder.initState()\n","                encoder_output, encoder_hidden, encoder_state = encoder(x, encoder_hidden, encoder_state)\n","                \n","                if decoder_layers > encoder_layers:\n","                    i = decoder_layers\n","                    decoder_hidden = encoder_hidden\n","                    decoder_state = encoder_state\n","                    \n","                    while True:\n","                        if i == encoder_layers:\n","                            break\n","                        # Concatenate the encoder hidden state and cell state to match the decoder layers\n","                        decoder_hidden = torch.cat([decoder_hidden, encoder_hidden[-1].unsqueeze(0)], dim=0)\n","                        decoder_state = torch.cat([decoder_state, encoder_state[-1].unsqueeze(0)], dim=0)\n","                        i -= 1\n","                \n","                elif decoder_layers < encoder_layers:\n","                    decoder_hidden = encoder_hidden[-decoder_layers:]\n","                    decoder_state = encoder_state[-decoder_layers:]\n","                else:\n","                    decoder_hidden = encoder_hidden\n","                    decoder_state = encoder_state\n","                \n","                decoder_input = y[0]\n","                \n","                if bi_directional == \"Yes\":\n","                    # Split the encoder output tensor into two parts along the last dimension\n","                    split_tensor = torch.split(encoder_output, hidden_size, dim=-1)\n","                    # Average the two parts\n","                    encoder_output = torch.add(split_tensor[0], split_tensor[1]) / 2\n","                \n","                # Run the decoder for each timestep in the output sequence\n","                for i in range(0, len(y)):\n","                    if attention == \"Yes\":\n","                        decoder_output, decoder_hidden, decoder_state, attn_weights = decoder(decoder_input, decoder_hidden, encoder_output, len(x), decoder_state)\n","                        max_prob, index = decoder_output.topk(1)\n","                        loss += loss_fun(torch.squeeze(decoder_output), y[i])\n","                        index = index.squeeze()\n","                        decoder_input = index\n","                        decoder_words.append(index.tolist())\n","                        if build_matrix:\n","                            attn.append(attn_weights)\n","                    else:\n","                        decoder_output, decoder_hidden, decoder_state = decoder(decoder_input, decoder_hidden, decoder_state)\n","                        max_prob, index = decoder_output.topk(1)\n","                        loss += loss_fun(torch.squeeze(decoder_output), y[i])\n","                        index = index.squeeze()\n","                        decoder_input = index\n","                        decoder_words.append(index.tolist())\n","                \n","                if build_matrix:\n","                    attention_matrix = torch.cat(tuple(x for x in attn), dim=2).to(device)\n","                \n","                decoder_words = np.array(decoder_words)\n","                pred_words.append(decoder_words.T)\n","                total_loss += loss.item()\n","        \n","        predictions = []\n","        for batch in pred_words:\n","            for word in batch:\n","                predictions.append(word)\n","        \n","        return predictions, total_loss / (len(predictions) * len(predictions[0])), attention_matrix\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def accuracy(predictions,y):\n","    count=0\n","    for i in range(0,len(predictions)):\n","        p=predictions[i]\n","        if np.array_equal(p,y[i]):\n","            count+=1\n","    return (count/len(predictions))*100"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## INTEGRATING WITH WANDB"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def wandb_run_sweeps(train_dataset,val_dataset,test_dataset,train_y,val_y,test_y,input_len,target_len):\n","    \n","    config = {\n","        \"project\":\"CS6910_Assignment3\",\n","        \"method\": 'bayes',\n","        \"metric\": {\n","        'name': 'acc',\n","        'goal': 'maximize'\n","        },\n","        'parameters' :{\n","        \"epochs\": {\"values\":[15,20,25]},\n","        \"batchsize\": {\"values\": [64,128,256]},\n","        \"embedding_size\": {\"values\":[256, 512,1024]},\n","        \"hidden_size\": {\"values\":[256, 512,1024]},\n","        \"encoder_layers\": {\"values\":[2,3,4]},\n","        \"decoder_layers\": {\"values\":[2,3,4]},\n","        \"cell_type\": {\"values\":[\"LSTM\"]},\n","        \"bi_directional\":{\"values\":[\"Yes\"]},\n","        \"dropout\":{\"values\":[0.2,0.3,0.5]},\n","        \"attention\":{\"values\":[\"No\"]},\n","        }\n","    }\n","    def train_rnn():\n","        wandb.init()\n","\n","        name='_CT_'+str(wandb.config.cell_type)+\"_BS_\"+str(wandb.config.batchsize)+\"_EPOCH_\"+str(wandb.config.epochs)+\"_ES_\"+str(wandb.config.embedding_size)+\"_HS_\"+str(wandb.config.hidden_size)\n","        \n","        \n","        train_dataloader=DataLoader(train_dataset,batch_size=wandb.config.batchsize)\n","        test_dataloader=DataLoader(test_dataset,batch_size=wandb.config.batchsize)\n","        val_dataloader=DataLoader(val_dataset,batch_size=wandb.config.batchsize)\n","        \n","        epoch_train_loss,epoch_val_loss,epoch_val_acc,encoder,decoder,encoder_layers,decoder_layers=train_iter(train_dataloader,val_dataloader,val_y,input_len,target_len,wandb.config.epochs,wandb.config.batchsize,wandb.config.embedding_size,wandb.config.encoder_layers,wandb.config.decoder_layers,wandb.config.hidden_size,wandb.config.cell_type,wandb.config.bi_directional,wandb.config.dropout,wandb.config.attention)\n","\n","        for i in range(wandb.config.epochs):\n","            wandb.log({\"loss\":epoch_train_loss[i]})\n","            wandb.log({\"val_loss\":epoch_val_loss[i]})\n","            wandb.log({\"val_acc\":epoch_val_acc[i]})\n","            wandb.log({\"epoch\": (i+1)})\n","        wandb.log({\"validation_accuracy\":epoch_val_acc[-1]})    \n","        \n","        train_predictions,_,_=eval(train_dataloader,encoder,decoder,wandb.config.encoder_layers,\n","                              wandb.config.decoder_layers,wandb.config.batchsize,wandb.config.hidden_size,\n","                              wandb.config.bi_directional,wandb.config.cell_type,wandb.config.attention)\n","\n","        train_accuracy=accuracy(train_predictions,train_y)\n","        wandb.log({\"train_accuracy\":train_accuracy})\n","        \n","        test_predictions,_,_=eval(test_dataloader,encoder,decoder,wandb.config.encoder_layers,\n","                              wandb.config.decoder_layers,wandb.config.batchsize,wandb.config.hidden_size,\n","                              wandb.config.bi_directional,wandb.config.cell_type,wandb.config.attention)\n","\n","        test_accuracy=accuracy(test_predictions,test_y)\n","        wandb.log({\"test_accuracy\":test_accuracy})\n","        wandb.log({\"acc\":epoch_val_acc[-1]})\n","        wandb.run.name = name\n","        wandb.run.save()\n","        wandb.run.finish()\n","    wandb.login(key=\"aecb4b665a37b40204530b0627a42274aeddd3e1\")\n","    sweep_id=wandb.sweep(config,project=\"CS6910_Assignment3\")\n","    wandb.agent(sweep_id,function=train_rnn)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def wandb_run_configuration(train_dataset,val_dataset,test_dataset,train_y,val_y,test_x,test_y,epochs,encoder_layers,decoder_layers,batchsize,embedding_size,hidden_size,bi_directional,dropout,cell_type,attention):\n","    \n","    wandb.login(key = \"aecb4b665a37b40204530b0627a42274aeddd3e1\")\n","    wandb.init(project=\"CS6910_Assignment3\")\n","    name='_CT_'+str(cell_type)+\"_BS_\"+str(batchsize)+\"_EPOCH_\"+str(epochs)+\"_ES_\"+str(embedding_size)+\"_HS_\"+str(hidden_size)\n","\n","\n","    train_dataloader=DataLoader(train_dataset,batch_size=batchsize)\n","    test_dataloader=DataLoader(test_dataset,batch_size=batchsize)\n","    val_dataloader=DataLoader(val_dataset,batch_size=batchsize)\n","\n","    epoch_train_loss,epoch_val_loss,epoch_val_acc,encoder,decoder,encoder_layers,decoder_layers=train_iter(train_dataloader,val_dataloader,val_y,input_len,target_len,epochs,batchsize,embedding_size,encoder_layers,decoder_layers,hidden_size,cell_type,bi_directional,dropout,attention)\n","\n","    for i in range(epochs):\n","        wandb.log({\"loss\":epoch_train_loss[i]})\n","        wandb.log({\"val_loss\":epoch_val_loss[i]})\n","        wandb.log({\"val_acc\":epoch_val_acc[i]})\n","        wandb.log({\"epoch\": (i+1)})\n","    wandb.log({\"validation_accuracy\":epoch_val_acc[-1]})    \n","\n","    train_predictions,_,_=eval(train_dataloader,encoder,decoder,encoder_layers,decoder_layers,batchsize,hidden_size,bi_directional,cell_type,attention)\n","\n","    train_accuracy=accuracy(train_predictions,train_y)\n","    wandb.log({\"train_accuracy\":train_accuracy})\n","\n","    test_predictions,_,_=eval(test_dataloader,encoder,decoder,encoder_layers,decoder_layers,batchsize,hidden_size,bi_directional,cell_type,attention)\n","    test_accuracy=accuracy(test_predictions,test_y)\n","    wandb.log({\"test_accuracy\":test_accuracy})\n","    wandb.log({\"acc\":epoch_val_acc[-1]})\n","    \n","    \n","    test_dataset_attn=MyDataset(test_x[:batchsize],test_y[:batchsize])\n","    test_dataloader_attn_for_matrix=DataLoader(test_dataset_attn,batch_size=batchsize)\n","    test_predictions,_,attn_matrix=eval(test_dataloader_attn_for_matrix,encoder,decoder,encoder_layers,decoder_layers,batchsize,hidden_size,bi_directional,cell_type,attention,True)\n","\n","    \n","    fig=plot_attention(test_predictions,attn_matrix)\n","    fig.savefig(\"ex.png\")\n","    temp = plt.imread(\"ex.png\")\n","    plt.show()\n","    image = wandb.Image(temp)\n","    wandb.log({\"attention heatmaps\":image})\n","    wandb.run.name = name\n","    wandb.run.save()\n","    wandb.run.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def main():\n","    train_df,test_df,val_df,eng_to_idx,hin_to_idx,idx_to_eng,idx_to_hin,input_len,target_len=get_data()\n","\n","    train_x,train_y = pre_process(train_df,eng_to_idx,hin_to_idx)\n","    test_x,test_y = pre_process(test_df,eng_to_idx,hin_to_idx)\n","    val_x,val_y = pre_process(val_df,eng_to_idx,hin_to_idx)\n","\n","    train_dataset=MyDataset(train_x,train_y)\n","    test_dataset=MyDataset(test_x,test_y)\n","    val_dataset=MyDataset(val_x,val_y)\n","\n","    wandb_run_sweeps(train_dataset,val_dataset,test_dataset,train_y,val_y,test_y,input_len,target_len)\n","\n","\n","if __name__==\"__main__\":\n","    main()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def representation_to_hin_word(predictions,idx_to_hin):\n","    words=[]\n","    for word in predictions:\n","        s=''\n","        for char in word:\n","            if(idx_to_hin[char]!='#' and idx_to_hin[char]!='^'):\n","                s+=idx_to_hin[char]\n","        words.append(s)\n","    return words\n","\n","def representation_to_eng_word(predictions,idx_to_eng):\n","    words=[]\n","    for word in predictions:\n","        s=''\n","        for char in word:\n","            if(idx_to_eng[char]!='#' and idx_to_eng[char]!='^'):\n","                s+=idx_to_eng[char]\n","        words.append(s)\n","    return words"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def make_csv_file(test_x,test_y,test_predictions,idx_to_eng,idx_to_hin):\n","    test_eng_words=representation_to_eng_word(test_x,idx_to_eng)\n","    pred_test_words=representation_to_hin_word(test_predictions,idx_to_hin)\n","    test_hin_words=representation_to_hin_word(test_y,idx_to_hin)\n","    # Sample data to write to the CSV file\n","    data1 = [\n","        ['Input', 'Expected', 'Predicted']\n","    ]\n","\n","\n","    for i in range(len(test_eng_words)):\n","        data1.append([test_eng_words[i],pred_test_words[i],test_hin_words[i]])\n","    # Specify the file path and name for the CSV file\n","    csv_file_path = 'data1.csv'\n","\n","    # Open the CSV file in write mode\n","    with open(csv_file_path, mode='w', newline='') as file:\n","        # Create a CSV writer object\n","        writer = csv.writer(file)\n","\n","        # Write the data to the CSV file row by row\n","        for row in data1:\n","            writer.writerow(row)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def plot_attention(test_predictions,attn_matrix):\n","    \n","    attn_matrix1=attn_matrix.permute(1,0,2)\n","    attn_matrix1=attn_matrix1[:9]\n","    total_words,input_length,output_length = attn_matrix1.shape\n","\n","\n","    from matplotlib.font_manager import FontProperties\n","\n","\n","    tel_font = FontProperties(fname = '/kaggle/input/hindi-font/TiroDevanagariHindi-Regular.ttf')\n","\n","\n","    fig, axes = plt.subplots(3, 3, figsize=(12,12))\n","\n","    fig.tight_layout(pad=5.0)\n","    fig.subplots_adjust(top=0.90)\n","    axes = axes.ravel()\n","\n","    for i in range(total_words):\n","        count=0\n","        start1=0\n","        end1=0\n","        eng_word=\"\"\n","        for char in test_x[i]:\n","            if(idx_to_eng[char]=='^'):\n","                start1=count+1\n","            elif(idx_to_eng[char]=='#'):\n","                end1=count\n","                break\n","            else:\n","                eng_word+=idx_to_eng[char]\n","            count+=1\n","\n","        count=0\n","        hin_word=\"\"\n","        for char in test_predictions[i]:\n","            if(idx_to_hin[char]=='^'):\n","                start=count+1\n","            elif(idx_to_hin[char]=='#'):\n","                end=count\n","                break\n","            else:\n","                hin_word+=idx_to_hin[char]\n","            count+=1\n","\n","        attn=attn_matrix1[i,start1:end1,start:end].cpu().numpy()\n","        sns.heatmap(attn, ax=axes[i],cmap=\"Greens\")\n","        axes[i].set_yticklabels(eng_word,rotation=10)  \n","        axes[i].set_xticklabels(hin_word,fontproperties = tel_font,fontdict={'fontsize':16})\n","        axes[i].xaxis.tick_top()\n","    \n","    return fig"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":4}
